            for i, (li, wi, ti) in enumerate(morph_data[idx]):
                hidden_layer = (h0[i].view(h0.size(1),1,-1).contiguous(), h1[i].view(h1.size(1),1,-1).contiguous())

                # Encoder morpheme
                input_tensor = torch.cat((wi, ti))
                target_length = li.size(0)

                encoder_output, _hs = engine.encoder._forward([input_tensor], hidden=hidden_layer)
                encoder_outputs[i,:] = encoder_output[0] # 1 x 1 x |E|

                # Decode morpheme
                decoder_input = torch.tensor([[SOS_token]], device=engine.device)

                decoder_hidden = _hs[0][-1].view(1,1,-1)
                h0[i], h1[i] = _hs[0].permute(1,0,2)[0], _hs[1].permute(1,0,2)[0]

                use_teacher_forcing = True if random.random() < 1.0 else False

                li = li.view(-1, 1).to(engine.device)
                if use_teacher_forcing:
                    # Teacher forcing: Feed the target as the next input
                    for di in range(target_length):
                        decoder_output, decoder_hidden, decoder_attention = engine.decoder._forward(
                            decoder_input, decoder_hidden, encoder_outputs)
                        meme_loss += engine.morpheme_criterion(decoder_output, li[di])
                        decoder_input = li[di]  # Teacher forcing

                else:
                    # Without teacher forcing: use its own predictions as the next input
                    for di in range(target_length):
                        decoder_output, decoder_hidden, decoder_attention = engine.decoder._forward(
                            decoder_input, decoder_hidden, encoder_outputs)
                        topv, topi = decoder_output.topk(1)
                        decoder_input = topi.squeeze().detach()  # detach from history as input

                        meme_loss += engine.morpheme_criterion(decoder_output, li[di])
                        if decoder_input.item() == EOS_token:
                            break
                # one iteration then break
                break

#####################################################################

            lemma, input_list = zip(*morph_data[idx])
            lemma_tensor = torch.stack(lemma).transpose(0,1).to(engine.device) #for loss calc

            encoder_output, enc_hidden = engine.encoder._forward(input_list, hidden=enc_hidden)
            decoder_input = torch.tensor([[SOS_token]*morph_data.batch_size], device=engine.device)
            decoder_hidden = enc_hidden[0][-1] # last layer of the hidden state

            for di in range(MAX_LENGTH):
                decoder_output, decoder_hidden, _ = engine.decoder._forward(
                    decoder_input, decoder_hidden, encoder_output)
                topv, topi = decoder_output.topk(1)
                decoder_input = topi.squeeze().detach()  # detach from history as input

                meme_loss += engine.morpheme_criterion(decoder_output, lemma_tensor[di])
  

